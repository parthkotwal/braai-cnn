{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5zB7-Fqesfs3"
   },
   "source": [
    "### Model Structure\n",
    "| Layer             |\n",
    "| ----------------- |\n",
    "| `Conv2D(16, 3x3)` |\n",
    "| `Conv2D(16, 3x3)` |\n",
    "| `MaxPool2D(2x2)`  |\n",
    "| `Dropout`         |\n",
    "| `Conv2D(32, 3x3)` |\n",
    "| `Conv2D(32, 3x3)` |\n",
    "| `MaxPool2D(4x4)`  |\n",
    "| `Dropout`         |\n",
    "| `Flatten`         |\n",
    "| `Dense(256)`      |\n",
    "| `Dropout`         |\n",
    "| `Dense(1)`        |\n",
    "\n",
    "![BRAAI CNN Model Structure](images/fig-braai.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 35803,
     "status": "ok",
     "timestamp": 1752691653878,
     "user": {
      "displayName": "Parth Kotwal",
      "userId": "02613118724001680014"
     },
     "user_tz": -330
    },
    "id": "k3UKNjfkvdgk",
    "outputId": "eecc8e55-b85a-4116-c542-5175496983db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6247,
     "status": "ok",
     "timestamp": 1752691660129,
     "user": {
      "displayName": "Parth Kotwal",
      "userId": "02613118724001680014"
     },
     "user_tz": -330
    },
    "id": "5vu7MVdqpvBr",
    "outputId": "0ef28a9a-c1e8-4cad-ec69-c99bc23c1085"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<cupy._io.npz.NpzFile at 0x7d03ab44f950>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cupy as np\n",
    "\n",
    "dataset_dir = \"/content/drive/MyDrive/braai_cnn/\"\n",
    "dataset_path = dataset_dir + \"ztf_dataset_split.npz\"\n",
    "data = np.load(dataset_path)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1020,
     "status": "ok",
     "timestamp": 1752691661150,
     "user": {
      "displayName": "Parth Kotwal",
      "userId": "02613118724001680014"
     },
     "user_tz": -330
    },
    "id": "bD-xSUn-vxOZ",
    "outputId": "4229cc13-411a-4c65-c8d4-e458060d2126"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OS                           : Linux-6.1.123+-x86_64-with-glibc2.35\n",
      "Python Version               : 3.11.13\n",
      "CuPy Version                 : 13.3.0\n",
      "CuPy Platform                : NVIDIA CUDA\n",
      "NumPy Version                : 2.0.2\n",
      "SciPy Version                : 1.15.3\n",
      "Cython Build Version         : 0.29.36\n",
      "Cython Runtime Version       : 3.0.12\n",
      "CUDA Root                    : /usr/local/cuda\n",
      "nvcc PATH                    : /usr/local/cuda/bin/nvcc\n",
      "CUDA Build Version           : 12060\n",
      "CUDA Driver Version          : 12040\n",
      "CUDA Runtime Version         : 12060 (linked to CuPy) / 12050 (locally installed)\n",
      "CUDA Extra Include Dirs      : ['/usr/local/lib/python3.11/dist-packages/nvidia/cuda_runtime/include']\n",
      "cuBLAS Version               : (available)\n",
      "cuFFT Version                : 11203\n",
      "cuRAND Version               : 10306\n",
      "cuSOLVER Version             : (11, 6, 3)\n",
      "cuSPARSE Version             : (available)\n",
      "NVRTC Version                : (12, 5)\n",
      "Thrust Version               : 200600\n",
      "CUB Build Version            : 200600\n",
      "Jitify Build Version         : <unknown>\n",
      "cuDNN Build Version          : (not loaded; try `import cupy.cuda.cudnn` first)\n",
      "cuDNN Version                : (not loaded; try `import cupy.cuda.cudnn` first)\n",
      "NCCL Build Version           : 21602\n",
      "NCCL Runtime Version         : 22203\n",
      "cuTENSOR Version             : None\n",
      "cuSPARSELt Build Version     : None\n",
      "Device 0 Name                : NVIDIA L4\n",
      "Device 0 Compute Capability  : 89\n",
      "Device 0 PCI Bus ID          : 0000:00:03.0\n"
     ]
    }
   ],
   "source": [
    "np.show_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 185,
     "status": "ok",
     "timestamp": 1752691661337,
     "user": {
      "displayName": "Parth Kotwal",
      "userId": "02613118724001680014"
     },
     "user_tz": -330
    },
    "id": "UoS3iWnZbtnh",
    "outputId": "e13dbfe7-e92d-4a20-ba6e-68a9a9ad91b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Jul 16 18:47:40 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA L4                      Off |   00000000:00:03.0 Off |                    0 |\n",
      "| N/A   39C    P0             16W /   72W |     189MiB /  23034MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "if gpu_info.find('failed') >= 0:\n",
    "  print('Not connected to a GPU')\n",
    "else:\n",
    "  print(gpu_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 26243,
     "status": "ok",
     "timestamp": 1752691687696,
     "user": {
      "displayName": "Parth Kotwal",
      "userId": "02613118724001680014"
     },
     "user_tz": -330
    },
    "id": "3mnUVdJZqxJk",
    "outputId": "72030983-541e-4751-f335-d1060a27f430"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((28776, 3, 63, 63), (28776,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data[\"X_train\"].astype(np.float16)\n",
    "y = data[\"y_train\"].astype(np.int8)\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1752691687705,
     "user": {
      "displayName": "Parth Kotwal",
      "userId": "02613118724001680014"
     },
     "user_tz": -330
    },
    "id": "iaOLKQtc1XaD"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "t = 1000 * time.time()\n",
    "np.random.seed(int(t) % 2**30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1752691687721,
     "user": {
      "displayName": "Parth Kotwal",
      "userId": "02613118724001680014"
     },
     "user_tz": -330
    },
    "id": "HPAkpqB_rzM_"
   },
   "outputs": [],
   "source": [
    "# Layer inteface\n",
    "class Layer:\n",
    "    def __init__(self):\n",
    "        self.input = None\n",
    "        self.output = None\n",
    "\n",
    "    def forward(self, input):\n",
    "        pass\n",
    "\n",
    "    def backward(self, d_out, lr):\n",
    "        pass\n",
    "\n",
    "    def get_parameters(self):\n",
    "        params = []\n",
    "        if hasattr(self, 'kernels'):\n",
    "            params.append(self.kernels)\n",
    "        if hasattr(self, 'biases'):\n",
    "            params.append(self.biases)\n",
    "        if hasattr(self, 'weights'):\n",
    "            params.append(self.weights)\n",
    "        return params\n",
    "\n",
    "    def get_gradients(self):\n",
    "        grads = []\n",
    "        if hasattr(self, 'kernels_grad'):\n",
    "            grads.append(self.kernels_grad)\n",
    "        if hasattr(self, 'biases_grad'):\n",
    "            grads.append(self.biases_grad)\n",
    "        if hasattr(self, 'weights_grad'):\n",
    "            grads.append(self.weights_grad)\n",
    "        return grads\n",
    "\n",
    "\n",
    "    def set_parameters(self, params):\n",
    "        i = 0\n",
    "        if hasattr(self, 'kernels'):\n",
    "            self.kernels = params[i]\n",
    "            i += 1\n",
    "        if hasattr(self, 'biases'):\n",
    "            self.biases = params[i]\n",
    "            i += 1\n",
    "        if hasattr(self, 'weights'):\n",
    "            self.weights = params[i]\n",
    "            i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1752691687745,
     "user": {
      "displayName": "Parth Kotwal",
      "userId": "02613118724001680014"
     },
     "user_tz": -330
    },
    "id": "UVGR6QGIdIVo"
   },
   "outputs": [],
   "source": [
    "class Adam:\n",
    "    def __init__(self, params, lr, beta1, beta2, epsilon):\n",
    "        self.params = params\n",
    "        self.m = [np.zeros_like(param) for param in params]\n",
    "        self.v = [np.zeros_like(param) for param in params]\n",
    "        self.lr = lr\n",
    "        self.beta1 = beta1\n",
    "        self.beta2 = beta2\n",
    "        self.epsilon = epsilon\n",
    "        self.t = 0\n",
    "\n",
    "    def step(self, grads):\n",
    "        self.t += 1\n",
    "        for i in range(len(self.params)):\n",
    "            g = grads[i]\n",
    "            self.m[i] = self.beta1 * self.m[i] + (1-self.beta1)*g\n",
    "            self.v[i] = self.beta2 * self.v[i] + (1-self.beta2)*(g**2)\n",
    "\n",
    "            m_hat = self.m[i] / (1 - self.beta1**self.t)\n",
    "            v_hat = self.v[i] / (1 - self.beta2**self.t)\n",
    "\n",
    "            self.params[i] -= self.lr * (m_hat / (self.epsilon + np.sqrt(v_hat)))\n",
    "\n",
    "    def collect_params(self):\n",
    "        return self.params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1752691687764,
     "user": {
      "displayName": "Parth Kotwal",
      "userId": "02613118724001680014"
     },
     "user_tz": -330
    },
    "id": "Yd5bUMcjqLAQ"
   },
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "from cupy.lib.stride_tricks import sliding_window_view\n",
    "\n",
    "# Converts NCHW input to column matrix\n",
    "def im2col(input, KH, KW, stride=1):\n",
    "      N, C, H, W = input.shape\n",
    "      OH = (H - KH) // stride + 1\n",
    "      OW = (W - KW) // stride + 1\n",
    "\n",
    "      patches = sliding_window_view(input, (KH, KW), axis=(2,3))\n",
    "      patches = patches[:, :, ::stride, ::stride, :, :]\n",
    "      cols = patches.transpose(0,2,3,1,4,5).reshape(N*OH*OW, -1)\n",
    "      return cols, OH, OW\n",
    "\n",
    "# Reverse of im2col for accumulating gradients to x\n",
    "def col2im(cols, input_shape, KH, KW, stride=1):\n",
    "    N, C, H, W = input_shape\n",
    "    OH = (H - KH) // stride + 1\n",
    "    OW = (W - KW) // stride + 1\n",
    "\n",
    "    patches = cols.reshape(N, OH, OW, C, KH, KW).transpose(0, 3, 4, 5, 1, 2)\n",
    "    x_grad = np.zeros(input_shape, dtype=cols.dtype)\n",
    "\n",
    "    for i in range(KH):\n",
    "        for j in range(KW):\n",
    "            x_grad[:, :, i:i+stride*OH:stride, j:j+stride*OW:stride] += patches[:, :, i, j]\n",
    "    return x_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 66,
     "status": "ok",
     "timestamp": 1752691687831,
     "user": {
      "displayName": "Parth Kotwal",
      "userId": "02613118724001680014"
     },
     "user_tz": -330
    },
    "id": "aq61XrPMtmUJ",
    "outputId": "aded2d59-1fca-482c-e346-8584c5eeedce"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/cupyx/jit/_interface.py:173: FutureWarning: cupyx.jit.rawkernel is experimental. The interface can change in the future.\n",
      "  cupy._util.experimental('cupyx.jit.rawkernel')\n"
     ]
    }
   ],
   "source": [
    "from cupyx.scipy.signal import correlate2d, convolve2d\n",
    "\n",
    "class Conv2D(Layer):\n",
    "    def __init__(self, kernel_size, output_depth):\n",
    "        self.output_depth = output_depth\n",
    "        self.kernel_size = kernel_size\n",
    "        self.initialized = False\n",
    "\n",
    "    def initialize_layer(self, input_shape):\n",
    "        N, self.input_depth, H, W = input_shape\n",
    "        self.KH = self.kernel_size\n",
    "        self.KW = self.kernel_size\n",
    "        self.OH = H - self.KH + 1\n",
    "        self.OW = W - self.KW + 1\n",
    "\n",
    "        fan_in = self.input_depth * self.KH * self.KW\n",
    "        self.kernels = np.random.randn(self.output_depth, self.input_depth, self.KH, self.KW) * np.sqrt(2.0 / fan_in).astype(np.float16)\n",
    "        self.biases = np.random.randn(self.output_depth).astype(np.float16)\n",
    "        self.initialized = True\n",
    "\n",
    "    def forward(self, input):\n",
    "        if not self.initialized:\n",
    "            self.initialize_layer(input.shape)\n",
    "\n",
    "        self.input = input\n",
    "        # 1. im2 col: all patches in one big matrix\n",
    "        cols = im2col(input, self.KH, self.KW)[0]\n",
    "\n",
    "        # 2. reshape kernels to 2D\n",
    "        W_col = self.kernels.reshape(self.output_depth, -1)\n",
    "\n",
    "        # 3. GEMM\n",
    "        out_cols = cols @ W_col.T\n",
    "        out_cols += self.biases\n",
    "\n",
    "        # 4. Reshape back to OG\n",
    "        N = input.shape[0]\n",
    "        self.output = out_cols.reshape(N, self.OH, self.OW, self.output_depth).transpose(0,3,1,2)\n",
    "        return self.output\n",
    "\n",
    "    def backward(self, d_out, lr):\n",
    "        N = d_out.shape[0]\n",
    "\n",
    "        # 1. flatten d_out to columns\n",
    "        d_cols = d_out.transpose(0,2,3,1).reshape(-1, self.output_depth)\n",
    "\n",
    "        # 2. grad kernels\n",
    "        cols = im2col(self.input, self.KH, self.KW)[0]\n",
    "        W_col_grad = d_cols.T @ cols\n",
    "        self.kernels_grad = W_col_grad.reshape(self.kernels.shape) / N\n",
    "\n",
    "        # 3. grad input cols\n",
    "        W_col = self.kernels.reshape(self.output_depth, -1)\n",
    "        cols_grad = d_cols @ W_col\n",
    "\n",
    "        # 4. col2im to get input gradient\n",
    "        input_grad = col2im(cols_grad, self.input.shape, self.KH, self.KW)\n",
    "\n",
    "        # 5) bias grad\n",
    "        self.biases_grad = d_out.sum(axis=(0,2,3)) / N\n",
    "        return input_grad\n",
    "\n",
    "    def get_gradients(self):\n",
    "      return [self.kernels_grad, self.biases_grad]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 57,
     "status": "ok",
     "timestamp": 1752691687898,
     "user": {
      "displayName": "Parth Kotwal",
      "userId": "02613118724001680014"
     },
     "user_tz": -330
    },
    "id": "uaAoRPaDs0aC"
   },
   "outputs": [],
   "source": [
    "class ReLU(Layer):\n",
    "    def forward(self, input):\n",
    "        self.input = input\n",
    "        return np.maximum(0, input)\n",
    "\n",
    "    def backward(self, d_out, lr):\n",
    "        # Relu prime\n",
    "        # print(f\"{self.__class__.__name__} received grad of shape {d_out.shape}\")\n",
    "\n",
    "        return d_out * (self.input > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 138,
     "status": "ok",
     "timestamp": 1752691688043,
     "user": {
      "displayName": "Parth Kotwal",
      "userId": "02613118724001680014"
     },
     "user_tz": -330
    },
    "id": "c6UDnwXYs2nn"
   },
   "outputs": [],
   "source": [
    "class Flatten(Layer):\n",
    "    def forward(self, input):\n",
    "        self.input_shape = input.shape # (N, C, H, W)\n",
    "        return input.reshape(self.input_shape[0], -1) # (N, C*H*W)\n",
    "\n",
    "    def backward(self, d_out, lr=None):\n",
    "        # print(f\"{self.__class__.__name__} received grad of shape {d_out.shape}\")\n",
    "\n",
    "        return d_out.reshape(self.input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1752691688079,
     "user": {
      "displayName": "Parth Kotwal",
      "userId": "02613118724001680014"
     },
     "user_tz": -330
    },
    "id": "VNiXS4T8s39h"
   },
   "outputs": [],
   "source": [
    "class MaxPool2D(Layer):\n",
    "    def __init__(self, pool_size=2, stride=2):\n",
    "        self.pool_size = pool_size\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, input):\n",
    "        self.input = input\n",
    "        N, C, H, W = input.shape\n",
    "\n",
    "        patches, OH, OW = im2col(input, self.pool_size, self.pool_size, stride=self.stride)\n",
    "        patches = patches.reshape(-1, C, self.pool_size*self.pool_size)\n",
    "        self.argmax = patches.argmax(axis=2)\n",
    "\n",
    "        out = patches.max(axis=2)\n",
    "        out = out.reshape(N, OH, OW, C).transpose(0,3,1,2)\n",
    "        return out\n",
    "\n",
    "    def backward(self, d_out, lr=None):\n",
    "        N, C, H, W = self.input.shape\n",
    "        # print(d_out.shape)\n",
    "        dum1, dum2, OH, OW = d_out.shape\n",
    "\n",
    "        d_flat = d_out.transpose(0,2,3,1).reshape(-1, C)\n",
    "        patches_grad = np.zeros((d_flat.shape[0], C, self.pool_size*self.pool_size), dtype=d_flat.dtype)\n",
    "\n",
    "        i = np.arange(patches_grad.shape[0])[:,None]\n",
    "        patches_grad[i, np.arange(C), self.argmax] = d_flat\n",
    "\n",
    "        cols_grad = patches_grad.reshape(-1, C*self.pool_size*self.pool_size)\n",
    "        return col2im(cols_grad, self.input.shape, self.pool_size, self.pool_size, stride=self.stride)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 27,
     "status": "ok",
     "timestamp": 1752691688107,
     "user": {
      "displayName": "Parth Kotwal",
      "userId": "02613118724001680014"
     },
     "user_tz": -330
    },
    "id": "_JDhhMcOs5IB"
   },
   "outputs": [],
   "source": [
    "class FC(Layer):\n",
    "    def __init__(self, input_size=None, output_size=None):\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.weights = None\n",
    "        self.biases = None\n",
    "\n",
    "    def forward(self, input):\n",
    "        self.input = input\n",
    "\n",
    "        if self.weights is None and self.output_size is not None:\n",
    "            self.input_size = input.shape[-1]\n",
    "            # self.weights = np.random.randn(self.output_size, self.input_size)\n",
    "            limit = np.sqrt(6 / (self.input_size + self.output_size))\n",
    "            self.weights = np.random.uniform(-limit, limit, (self.output_size, self.input_size))\n",
    "            self.biases = np.zeros(self.output_size)\n",
    "\n",
    "        if input.ndim == 1:\n",
    "            # print(\"Final FC output before sigmoid:\", input[:5].flatten())\n",
    "            return np.dot(self.weights, input) + self.biases\n",
    "        else:\n",
    "            # print(\"Final FC output before sigmoid:\", input[:5].flatten())\n",
    "\n",
    "            return np.dot(input, self.weights.T) + self.biases\n",
    "\n",
    "    def backward(self, d_out, lr):\n",
    "        # print(f\"[FC backward] d_out.shape={d_out.shape}, input.shape={self.input.shape}, weights.shape={self.weights.shape}\")\n",
    "        if self.input.ndim == 1 and self.weights is not None:\n",
    "            weights_gradient = np.outer(d_out, self.input)\n",
    "            input_gradient = np.dot(self.weights.T, d_out)\n",
    "        else:\n",
    "            weights_gradient = np.dot(d_out.T, self.input) / d_out.shape[0]\n",
    "            input_gradient = np.dot(d_out, self.weights)\n",
    "\n",
    "        self.weights_grad = weights_gradient\n",
    "        self.biases_grad = d_out.mean(axis=0) if d_out.ndim > 1 else d_out\n",
    "\n",
    "        return input_gradient\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1752691688145,
     "user": {
      "displayName": "Parth Kotwal",
      "userId": "02613118724001680014"
     },
     "user_tz": -330
    },
    "id": "3ST7RVd3s65-"
   },
   "outputs": [],
   "source": [
    "class Dropout(Layer):\n",
    "    def __init__(self, dropout_rate=0.5):\n",
    "        self.rate = dropout_rate\n",
    "        self.mask = None\n",
    "        self.training = True\n",
    "\n",
    "    def forward(self, input):\n",
    "        if self.training:\n",
    "            self.mask = (np.random.rand(*input.shape) > self.rate).astype(input.dtype)\n",
    "            return input * self.mask / (1.0 - self.rate)\n",
    "        else:\n",
    "            return input\n",
    "\n",
    "    def backward(self, d_out, lr=None):\n",
    "        if self.training:\n",
    "            return d_out * self.mask / (1.0 - self.rate)\n",
    "        else:\n",
    "            return d_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1752691688164,
     "user": {
      "displayName": "Parth Kotwal",
      "userId": "02613118724001680014"
     },
     "user_tz": -330
    },
    "id": "JQQ_WsXus8b9"
   },
   "outputs": [],
   "source": [
    "class Sigmoid(Layer):\n",
    "    def forward(self, input):\n",
    "        self.input = np.clip(input, -500, 500)\n",
    "        self.out = 1 / (1 + np.exp(-self.input))\n",
    "        return self.out\n",
    "\n",
    "    def backward(self, d_out, lr=None):\n",
    "        # print(f\"{self.__class__.__name__} received grad of shape {d_out.shape}\")\n",
    "        return d_out * self.out * (1-self.out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1752691688185,
     "user": {
      "displayName": "Parth Kotwal",
      "userId": "02613118724001680014"
     },
     "user_tz": -330
    },
    "id": "SmNFLyJ_s9qO"
   },
   "outputs": [],
   "source": [
    "def BCE(y_true, y_pred):\n",
    "    y_pred = np.clip(y_pred, 1e-15, 1-(1e-15))\n",
    "    return -(y_true*np.log(y_pred) + (1-y_true) * np.log(1-y_pred))\n",
    "\n",
    "def BCEG(y_true, y_pred):\n",
    "    y_pred = np.clip(y_pred, 1e-15, 1-(1e-15))\n",
    "    return (y_pred - y_true) / (y_pred * (1 - y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 303,
     "status": "ok",
     "timestamp": 1752692442481,
     "user": {
      "displayName": "Parth Kotwal",
      "userId": "02613118724001680014"
     },
     "user_tz": -330
    },
    "id": "RTztDH2atAJx"
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import cupy as np\n",
    "import gc\n",
    "\n",
    "class NumpyCNN:\n",
    "    def __init__(self):\n",
    "        self.layers = [\n",
    "            # Block 1\n",
    "            Conv2D(kernel_size=3, output_depth=16), ReLU(),\n",
    "            Conv2D(kernel_size=3, output_depth=16), ReLU(),\n",
    "            MaxPool2D(pool_size=2, stride=2),\n",
    "            Dropout(dropout_rate=0.25),\n",
    "\n",
    "            # Block 2\n",
    "            Conv2D(kernel_size=3, output_depth=32), ReLU(),\n",
    "            Conv2D(kernel_size=3, output_depth=32), ReLU(),\n",
    "            MaxPool2D(pool_size=2, stride=4),\n",
    "            Dropout(dropout_rate=0.25),\n",
    "\n",
    "            # Fully connected\n",
    "            Flatten(),\n",
    "            FC(input_size=1152, output_size=256), ReLU(),\n",
    "            Dropout(dropout_rate=0.5),\n",
    "            FC(input_size=256, output_size=1), Sigmoid()\n",
    "        ]\n",
    "\n",
    "    def forward(self, x):\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            if isinstance(layer, Dropout):\n",
    "                layer.training = True\n",
    "\n",
    "            # print(f\"Before layer #{i+1} {layer.__class__.__name__}: Input shape is {x.shape}\")\n",
    "            x = layer.forward(x)\n",
    "        return x\n",
    "\n",
    "    def backward(self, grad, lr):\n",
    "        for layer in reversed(self.layers):\n",
    "            grad = layer.backward(grad, lr)\n",
    "        return grad\n",
    "\n",
    "\n",
    "    def predict(self, X, batch_size=16):\n",
    "        self.eval()\n",
    "        preds = []\n",
    "        for i in range(0, len(X), batch_size):\n",
    "            x_batch = X[i:i+batch_size]\n",
    "            x = x_batch\n",
    "            for layer in self.layers:\n",
    "                if isinstance(layer, Dropout):\n",
    "                    layer.training = False\n",
    "                x = layer.forward(x)\n",
    "            preds.append(x)\n",
    "\n",
    "            gc.collect()\n",
    "            np.get_default_memory_pool().free_all_blocks()\n",
    "            np.cuda.Device().synchronize()\n",
    "\n",
    "        return np.concatenate(preds, axis=0)\n",
    "\n",
    "\n",
    "    def eval(self):\n",
    "        for layer in self.layers:\n",
    "            if isinstance(layer, Dropout):\n",
    "                layer.training = False\n",
    "\n",
    "\n",
    "    def save(self, filename):\n",
    "        save_dict = {}\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            ps = layer.get_parameters()\n",
    "            cpu_ps = [np.asnumpy(p) for p in ps]\n",
    "            for j, p in enumerate(cpu_ps):\n",
    "                save_dict[f\"layer_{i}_param_{j}\"] = p\n",
    "        numpy.savez(filename, **save_dict)\n",
    "        print(f\"Saved model at {filename}\")\n",
    "\n",
    "\n",
    "    def load(self, filename, input_shape):\n",
    "        dummy_input = np.zeros(input_shape)\n",
    "        self.predict(dummy_input)\n",
    "\n",
    "        data = numpy.load(filename, allow_pickle=True)\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            ps = []\n",
    "            j = 0\n",
    "            while True:\n",
    "                key = f\"layer_{i}_param_{j}\"\n",
    "                if key in data:\n",
    "                    ps.append(np.array(data[key]))\n",
    "                    j += 1\n",
    "                else:\n",
    "                    break\n",
    "            if ps:\n",
    "                layer.set_parameters(ps)\n",
    "\n",
    "\n",
    "        print(f\"Model from {filename} loaded into {type(self).__name__}\")\n",
    "\n",
    "\n",
    "    def collect_parameters(self):\n",
    "        params = []\n",
    "        for layer in self.layers:\n",
    "            params.extend(layer.get_parameters())\n",
    "        return params\n",
    "\n",
    "    def collect_gradients(self):\n",
    "        grads = []\n",
    "        for layer in self.layers:\n",
    "            if hasattr(layer, \"get_gradients\"):\n",
    "                grads.extend(layer.get_gradients())\n",
    "        return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "executionInfo": {
     "elapsed": 335,
     "status": "ok",
     "timestamp": 1752692303942,
     "user": {
      "displayName": "Parth Kotwal",
      "userId": "02613118724001680014"
     },
     "user_tz": -330
    },
    "id": "NOr8Eb-stCOy"
   },
   "outputs": [],
   "source": [
    "# import time\n",
    "\n",
    "def train(model, X_train, y_train, epochs, lr, batch_size, val_split, patience, save_path):\n",
    "    n = len(X_train)\n",
    "    split_index = int(n*(1-val_split))\n",
    "\n",
    "    X_val = X_train[split_index:]\n",
    "    y_val = y_train[split_index:]\n",
    "    X_train = X_train[:split_index]\n",
    "    y_train = y_train[:split_index]\n",
    "    n_train = len(X_train)\n",
    "\n",
    "    optimizer = None\n",
    "    best_val_loss = float('inf')\n",
    "    best_weights = None\n",
    "    epochs_without_improvement = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0.0\n",
    "        correct = 0\n",
    "\n",
    "\n",
    "        indices = np.random.permutation(n_train)\n",
    "        X_train = X_train[indices]\n",
    "        y_train = y_train[indices]\n",
    "\n",
    "        for start in range(0, n_train, batch_size):\n",
    "            # start_time = time.time()\n",
    "            end = start + batch_size\n",
    "            batch_x = X_train[start:end]\n",
    "            batch_y = y_train[start:end].reshape(-1, 1)\n",
    "\n",
    "            out = model.forward(batch_x)\n",
    "\n",
    "            if optimizer is None:\n",
    "                optimizer = Adam(\n",
    "                    model.collect_parameters(),\n",
    "                    lr=lr,\n",
    "                    beta1=0.9,\n",
    "                    beta2=0.999,\n",
    "                    epsilon=1e-8\n",
    "                )\n",
    "\n",
    "            loss = BCE(batch_y, out).mean()\n",
    "            grad = BCEG(batch_y, out)\n",
    "\n",
    "            total_loss += loss * batch_y.shape[0]\n",
    "            model.backward(grad, lr=None)\n",
    "            grads = model.collect_gradients()\n",
    "            optimizer.step(grads)\n",
    "\n",
    "            gc.collect()\n",
    "            np.get_default_memory_pool().free_all_blocks()\n",
    "            np.cuda.Device().synchronize()\n",
    "\n",
    "            preds = (out > 0.5).astype(int).flatten()\n",
    "            correct += np.sum(preds == batch_y.flatten())\n",
    "            # print(time.time()-start_time)\n",
    "\n",
    "        val_out = model.predict(X_val, batch_size=16)\n",
    "        val_loss = BCE(y_val.reshape(-1,1), val_out).mean()\n",
    "        val_preds = (val_out > 0.5).astype(int).flatten()\n",
    "        val_acc = np.mean(val_preds == y_val.flatten())\n",
    "\n",
    "        train_acc = correct / n_train\n",
    "        train_loss = total_loss/n_train\n",
    "        print(f\"Epoch {epoch+1}/{epochs} - Train Loss: {train_loss:.4f} — Train Acc: {train_acc:.4f} — Val Loss: {val_loss:.4f} — Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_weights = [np.copy(p) for p in model.collect_parameters()]\n",
    "            epochs_without_improvement = 0\n",
    "        else:\n",
    "            epochs_without_improvement += 1\n",
    "            if epochs_without_improvement >= patience:\n",
    "                print(f\"Early stopping triggered at epoch {epoch+1}\")\n",
    "                break\n",
    "\n",
    "    if best_weights:\n",
    "        param_id = 0\n",
    "        for layer in model.layers:\n",
    "            params = layer.get_parameters()\n",
    "            if params:\n",
    "                count = len(params)\n",
    "                layer.set_parameters(best_weights[param_id:param_id+count])\n",
    "                param_id += count\n",
    "\n",
    "    if save_path:\n",
    "        model.save(save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2622613,
     "status": "ok",
     "timestamp": 1752695076711,
     "user": {
      "displayName": "Parth Kotwal",
      "userId": "02613118724001680014"
     },
     "user_tz": -330
    },
    "id": "WOkd29SYtFps",
    "outputId": "2be8532d-385c-49b1-8567-0f8d09377f80"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 - Train Loss: 0.7173 — Train Acc: 0.5699 — Val Loss: 0.6377 — Val Acc: 0.6355\n",
      "Epoch 2/50 - Train Loss: 0.6169 — Train Acc: 0.6501 — Val Loss: 0.5716 — Val Acc: 0.6786\n",
      "Epoch 3/50 - Train Loss: 0.5740 — Train Acc: 0.6894 — Val Loss: 0.5651 — Val Acc: 0.6857\n",
      "Epoch 4/50 - Train Loss: 0.5546 — Train Acc: 0.7046 — Val Loss: 0.5205 — Val Acc: 0.7128\n",
      "Epoch 5/50 - Train Loss: 0.5390 — Train Acc: 0.7149 — Val Loss: 0.5392 — Val Acc: 0.7067\n",
      "Epoch 6/50 - Train Loss: 0.5217 — Train Acc: 0.7262 — Val Loss: 0.4868 — Val Acc: 0.7552\n",
      "Epoch 7/50 - Train Loss: 0.5088 — Train Acc: 0.7367 — Val Loss: 0.5102 — Val Acc: 0.7361\n",
      "Epoch 8/50 - Train Loss: 0.4957 — Train Acc: 0.7445 — Val Loss: 0.4819 — Val Acc: 0.7495\n",
      "Epoch 9/50 - Train Loss: 0.4877 — Train Acc: 0.7568 — Val Loss: 0.4523 — Val Acc: 0.7669\n",
      "Epoch 10/50 - Train Loss: 0.4726 — Train Acc: 0.7671 — Val Loss: 0.4500 — Val Acc: 0.7719\n",
      "Epoch 11/50 - Train Loss: 0.4644 — Train Acc: 0.7732 — Val Loss: 0.4432 — Val Acc: 0.7813\n",
      "Epoch 12/50 - Train Loss: 0.4595 — Train Acc: 0.7768 — Val Loss: 0.4524 — Val Acc: 0.7688\n",
      "Epoch 13/50 - Train Loss: 0.4516 — Train Acc: 0.7818 — Val Loss: 0.4402 — Val Acc: 0.7795\n",
      "Epoch 14/50 - Train Loss: 0.4466 — Train Acc: 0.7864 — Val Loss: 0.4246 — Val Acc: 0.7967\n",
      "Epoch 15/50 - Train Loss: 0.4397 — Train Acc: 0.7886 — Val Loss: 0.4074 — Val Acc: 0.8061\n",
      "Epoch 16/50 - Train Loss: 0.4394 — Train Acc: 0.7870 — Val Loss: 0.4310 — Val Acc: 0.7860\n",
      "Epoch 17/50 - Train Loss: 0.4269 — Train Acc: 0.7959 — Val Loss: 0.4139 — Val Acc: 0.7979\n",
      "Epoch 18/50 - Train Loss: 0.4276 — Train Acc: 0.7956 — Val Loss: 0.4268 — Val Acc: 0.7872\n",
      "Epoch 19/50 - Train Loss: 0.4174 — Train Acc: 0.8052 — Val Loss: 0.4196 — Val Acc: 0.8016\n",
      "Epoch 20/50 - Train Loss: 0.4132 — Train Acc: 0.8041 — Val Loss: 0.4188 — Val Acc: 0.7953\n",
      "Early stopping triggered at epoch 20\n",
      "Saved model at /content/drive/MyDrive/braai_cnn/models/numpy_cnn.npz\n"
     ]
    }
   ],
   "source": [
    "# np.cuda.runtime.deviceSynchronize()\n",
    "model = NumpyCNN()\n",
    "filename = \"/content/drive/MyDrive/braai_cnn/models/numpy_cnn.npz\"\n",
    "\n",
    "train(model, X, y, epochs=50, lr=0.001, batch_size=64, val_split=0.05, patience=5, save_path=filename)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOAfpAjA/BGR8D9fA+t8+p5",
   "gpuType": "L4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
